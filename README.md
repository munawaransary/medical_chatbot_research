# BengaliMed: A Culturally-Aware Medical Chatbot for Bengali Healthcare

## Overview
This repository contains the implementation of BengaliMed, a research-focused Bengali medical chatbot designed to provide culturally-appropriate healthcare assistance to Bengali speakers. This project aims to bridge the gap in medical AI resources for the 230M+ Bengali-speaking population worldwide.

## ğŸ¯ Research Objectives
- Create the first large-scale Bengali medical conversational dataset
- Develop a cultural adaptation framework for medical chatbots
- Establish evaluation methodologies for cross-lingual medical AI
- Provide an open-source Bengali medical chatbot system

## ğŸ—ï¸ Project Structure
```
medical_chatbot/
â”œâ”€â”€ README.md                    # Project overview and setup
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.py                     # Package installation
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ model_config.yaml       # Model hyperparameters
â”‚   â”œâ”€â”€ data_config.yaml        # Data processing settings
â”‚   â””â”€â”€ training_config.yaml    # Training configurations
â”œâ”€â”€ data/                        # Dataset storage
â”‚   â”œâ”€â”€ raw/                    # Original datasets
â”‚   â”œâ”€â”€ processed/              # Cleaned and processed data
â”‚   â”œâ”€â”€ translated/             # Bengali translations
â”‚   â””â”€â”€ augmented/              # Augmented datasets
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/                   # Data processing modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ translator.py       # Translation pipeline
â”‚   â”‚   â”œâ”€â”€ preprocessor.py     # Data cleaning and preprocessing
â”‚   â”‚   â”œâ”€â”€ augmentor.py        # Data augmentation
â”‚   â”‚   â””â”€â”€ validator.py        # Quality validation
â”‚   â”œâ”€â”€ models/                 # Model implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ bengali_medical_model.py  # Main model class
â”‚   â”‚   â”œâ”€â”€ cultural_adapter.py       # Cultural adaptation module
â”‚   â”‚   â””â”€â”€ fine_tuner.py            # Fine-tuning utilities
â”‚   â”œâ”€â”€ training/               # Training scripts
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py          # Main training loop
â”‚   â”‚   â”œâ”€â”€ evaluator.py        # Evaluation metrics
â”‚   â”‚   â””â”€â”€ callbacks.py        # Training callbacks
â”‚   â”œâ”€â”€ inference/              # Inference and deployment
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chatbot.py          # Main chatbot interface
â”‚   â”‚   â””â”€â”€ api.py              # REST API endpoints
â”‚   â””â”€â”€ utils/                  # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py           # Logging utilities
â”‚       â”œâ”€â”€ metrics.py          # Evaluation metrics
â”‚       â””â”€â”€ helpers.py          # General helper functions
â”œâ”€â”€ notebooks/                   # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb     # Dataset analysis
â”‚   â”œâ”€â”€ 02_translation_pipeline.ipynb # Translation experiments
â”‚   â”œâ”€â”€ 03_model_training.ipynb       # Training experiments
â”‚   â””â”€â”€ 04_evaluation.ipynb          # Results analysis
â”œâ”€â”€ scripts/                     # Utility scripts
â”‚   â”œâ”€â”€ download_data.py        # Data download automation
â”‚   â”œâ”€â”€ train_model.py          # Training script
â”‚   â”œâ”€â”€ evaluate_model.py       # Evaluation script
â”‚   â””â”€â”€ deploy_model.py         # Deployment script
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data/              # Data processing tests
â”‚   â”œâ”€â”€ test_models/            # Model tests
â”‚   â””â”€â”€ test_utils/             # Utility tests
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ research_paper_outline.md    # Paper structure
â”‚   â”œâ”€â”€ dataset_strategy.md          # Data creation strategy
â”‚   â”œâ”€â”€ project_roadmap.md           # Development roadmap
â”‚   â””â”€â”€ api_documentation.md         # API docs
â”œâ”€â”€ experiments/                 # Experiment tracking
â”‚   â”œâ”€â”€ logs/                   # Training logs
â”‚   â”œâ”€â”€ models/                 # Saved model checkpoints
â”‚   â””â”€â”€ results/                # Experiment results
â””â”€â”€ deployment/                  # Deployment configurations
    â”œâ”€â”€ docker/                 # Docker configurations
    â”œâ”€â”€ streamlit_app.py        # Demo application
    â””â”€â”€ requirements_deploy.txt  # Deployment dependencies
```

## ğŸš€ Quick Start

### 1. Environment Setup
```bash
# Clone the repository
git clone https://github.com/munawaransary/medical_chatbot_research.git
cd medical_chatbot_research

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Data Preparation
```bash
# Download datasets
python scripts/download_data.py

# Process and translate data
python scripts/process_data.py --config config/data_config.yaml
```

### 3. Model Training
```bash
# Train the model
python scripts/train_model.py --config config/training_config.yaml
```

### 4. Run Demo
```bash
# Start the Streamlit demo
streamlit run deployment/streamlit_app.py
```

## ğŸ“Š Datasets
- **Primary**: Kaggle AI Medical Chatbot datasets (English)
- **Secondary**: BanglaHealth paraphrase dataset (200K Bengali health sentences)
- **Augmentation**: Bengali medical textbooks and admission materials
- **Target Size**: 250K Bengali medical interactions

## ğŸ”¬ Research Contributions
1. **First large-scale Bengali medical conversational dataset**
2. **Cultural adaptation framework for medical chatbots**
3. **Cross-lingual medical knowledge transfer methodology**
4. **Comprehensive evaluation framework for Bengali medical AI**

## ğŸ“ˆ Performance Targets
- **Medical Accuracy**: >90% expert validation
- **Cultural Appropriateness**: >95% community approval
- **Linguistic Quality**: >85% native speaker satisfaction
- **Response Relevance**: >88% user satisfaction

## ğŸ¥ Specialized Domains
- **Mental Health**: Depression, anxiety, cultural sensitivity
- **Pediatric Medicine**: Child health, vaccination, development
- **Women's Health**: Reproductive health, pregnancy care
- **General Medicine**: Common symptoms, preventive care

## ğŸ› ï¸ Technology Stack
- **Framework**: PyTorch, Transformers (Hugging Face)
- **Models**: BanglaT5, mBERT, Custom Bengali embeddings
- **Translation**: Google Translate API + Manual correction
- **Database**: PostgreSQL for medical knowledge
- **Frontend**: Streamlit for demo, FastAPI for production
- **Deployment**: Docker containers, cloud-ready

## ğŸ“ Research Timeline (All these are tentative)
- **Phase 1** (Weeks 1-3): Literature review and dataset analysis
- **Phase 2** (Weeks 4-8): Data preparation and translation
- **Phase 3** (Weeks 9-16): Model development and training
- **Phase 4** (Weeks 17-20): Evaluation and validation
- **Phase 5** (Weeks 21-24): Research publication

<!-- ## ğŸ¯ Target Publications
- **Primary**: ACL 2025, EMNLP 2025
- **Secondary**: AMIA 2025, ICON 2025
- **Journal**: Journal of Medical Internet Research -->

## âš ï¸ Important Disclaimers
- This system is for research purposes only
- Not intended to replace professional medical advice
- Always consult healthcare professionals for medical decisions
- Cultural adaptations are based on general patterns and may not apply to all individuals

## ğŸ¤ Contributing
We welcome contributions from the research community. Please see our contribution guidelines and code of conduct.

## ğŸ“„ License
This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“ Contact
- **Researcher**: Mim Raihan, Munawar Mahtab Ansary
- **Institution**: BRACU
- **Email**: munawar.mahtab.ansary@g.bracu.ac.bd
- **Project Repository**: https://github.com/munawaransary/medical_chatbot_research

## ğŸ™ Acknowledgments
- BanglaHealth dataset creators
- Kaggle medical dataset contributors
- Bengali medical experts and linguists
- Open-source NLP community

---
*This project aims to democratize healthcare access for Bengali speakers through culturally-aware AI technology.*
